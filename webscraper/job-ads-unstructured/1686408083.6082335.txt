Computer Vision Engineer - Focus on Lidar and Radar Systems (m/f/d)
ANavS GmbH
München
Erstellen Sie ein Indeed-Konto, bevor Sie zur Website des Unternehmens weitergeleitet werden.
Weiter zur Bewerbung

Job advertisement Id FT008 online since 04/2023




ANavS – Advanced Navigation Solutions has three lines of business: precise positioning systems, precise mapping systems and snow monitoring systems. The core of the ANavS positioning systems is a modular and flexibly configurable sensor fusion of GNSS, inertial, odometry, UWB, camera and Lidar measurements. The innovative positioning algorithms were developed and patented by ANavS and include newest RTK/ PPP and AI methods. The main products of ANavS are the Multi-Sensor RTK module, the RTCM base station, and the Integrated Sensor Platform (ISP) with 3 integrated GNSS receivers, an IMU, a wheel odometry interface, 2 cameras, a 3D Lidar, an LTE module for the reception of RTK corrections, and a processor for the sensor fusion. The ANavS products have a large range of applications including the automotive, robotics, automation, maritime, railway, aerospace, agriculture and mining industries.

You will contribute to the integration of Lidar and Radar sensors into the existing Multi-GNSS/INS-based sensor fusion positioning system that already achieves centimeter-level accuracy in many scenarios. To bridge challenging GNSS scenarios such as tunnels, urban canyons or trees the fusion of Lidar/Radar-derived pose measurements from Lidar/Radar odometry or SLAM is desired. Besides the primary focus on precise positioning visual sensors are used for mapping and environment detection, which includes 3D point cloud and 2D road mapping, object detection and semantic segmentation.

Aside from computer vision another increasingly relevant topic is integrity monitoring, which may be part of your tasks. This includes monitoring of sensor data, intermediate system states and final positioning outputs to provide system status information and feedback to previous modules. GNSS spoofing detection is part of integrity monitoring in that manipulation of GNSS signals violates the system integrity. Computer vision can contribute to this task by providing alternative positioning solutions.

Your responsibility will cover the whole pipeline starting from the sensor’s integration to the algorithm development and up to the interface implementation for sensor fusion. The goal is the enhancement of our products, in particular our Integrated Sensor Platform (ISP), with real-time capable algorithms on embedded NVIDIA platforms. Accompanying this technical focus, you will take care of funded as well as customer projects that intersect with your technical expertise.

You will work in a small, flexible and growing team with flat hierarchies and expertise in computer vision, deep learning, software development, sensor fusion and embedded hardware development. You contribute to exciting manifold projects, for example in the automotive industry, and work together with partners such as BMW, Continental, Intel, Schaeffler and KIT. ANavS provides free drinks, fruits and snacks, and a kicker table, and is located in Munich Laim with direct connection to U-Bahn, Bus and S-Bahn.




Your tasks:
Development of algorithms for:
Lidar/Radar odometry and SLAM, to improve current positioning performance
2D/3D mapping, to generate precise maps for localization
Semantic segmentation and object detection, for environment detection
Application of state-of-the-art computer vision, machine learning and deep learning techniques
Potentially: Development of AI-based integrity monitoring algorithms, including machine learning based spoofing detection to provide system status and feedback
Implementation of interfaces between the computer vision and sensor fusion framework
Selection, evaluation and integration of Lidar and Radar sensors
Lidar/Radar sensor calibration and time synchronization (e.g. hardware triggering)
Integration of additional sensors, such as IMU, wheel odometry or GNSS-based pose measurements into computer vision approaches
Development of real-time solutions and docker containers for our embedded platforms
Responsibility for funded and customer projects
Bringing developed solutions towards product stage
Close cooperation with the hardware, software and sensor fusion team
Patenting and publishing of developed approaches is encouraged
Your profile:
Preferable 2 years’ experience in computer vision and machine learning/ deep learning
Computer science degree (or comparable)
Well-founded knowledge in SLAM techniques for localization and mapping
Well-founded knowledge in C++, Python and deep learning frameworks, such as PyTorch and TensorFlow.
Practical experience in training, developing and evaluating deep neural networks for computer vision
Preferable experience with Lidar/Radar sensors, calibration, integration and time synchronization
Preferable experience in ROS/ROS2, CARLA or Gazebo simulators
High motivation to contribute to the technical development, ability to work independently and willing to adapt to flexible tasks
Team player with quick perception, reliability and accuracy
Good communication skills in English and German
Diesen Job melden